{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import stats\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This lesson analyzes data from the following paper\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4878611/pdf/839.pdf\n",
    "\n",
    "#### How many biological replicates are needed in an RNA-seq experiment and which differential expression tool should you use?\n",
    "\n",
    "RNA-seq is now the technology of choice for genome-wide differential gene expression experiments, but it is not clear how many biological replicates are needed to ensure valid biological interpretation of the results or which statistical tools are best for analyzing the data. An RNA-seq experiment with 48 biological replicates in each of two conditions was performed to answer these questions and provide guidelines for experimental design. With three biological replicates, nine of the 11 tools evaluated found only 20%–40% of the significantly differentially expressed (SDE) genes identified with the full set of 42 clean replicates. This rises to >85% for the subset of SDE genes changing in expression by more than fourfold. To achieve >85% for all SDE genes regardless of fold change requires more than 20 biological replicates. The same nine tools successfully control their false discovery rate at ≲5% for all numbers of replicates, while the remaining two tools fail to control their FDR adequately, particularly for low numbers of replicates. For future RNA-seq experiments, these results suggest that at least six biological replicates should be used, rising to at least 12 when it is important to identify SDE genes for all fold changes. If fewer than 12 replicates are used, a superior combination of true positive and false positive performances makes edgeR and DESeq2 the leading tools. For higher replicate numbers, minimizing false positives is more important and DESeq marginally outperforms the other tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datafiles\n",
    "\n",
    "There are 96 separate datafiles, each representing the processed output of an RNAseq experiment looking at mRNA levels in wild-type (48 samples) or SNF2 deletion (48 samples) yeast cells grown under standard condition. \n",
    "\n",
    "The files are incredible simple. Two columns, separated by tabs. The first column is the gene name, the second column the normalized counts for that gene in that sample (read the paper if you're interested in how they did the counting and normalization).\n",
    "\n",
    "YBL013W 39\n",
    "YBL014C 127\n",
    "YBL015W 732\n",
    "YBL016W 309\n",
    "YBL017C 1613\n",
    "YBL018C 174\n",
    "YBL019W 117\n",
    "YBL020W 258\n",
    "YBL021C 248\n",
    "YBL022C 1168\n",
    "YBL023C 331\n",
    "YBL024W 451\n",
    "YBL025W 64\n",
    "YBL026W 206\n",
    "YBL027W 9723\n",
    "YBL028C 77\n",
    "YBL029C-A       157\n",
    "\n",
    "Most of the genes have this naming format:\n",
    "\n",
    "Systematic names for nuclear-encoded ORFs begin with the letter 'Y' (for 'Yeast'); the second letter denotes the chromosome number ('A' is chr I, 'B' is chr II, etc.); the third letter is either 'L' or 'R' for left or right chromosome arm; next is a three digit number indicating the order of the ORFs on that arm of a chromosome starting from the centromere, irrespective of strand; finally, there is an additional letter indicating the strand, either 'W' for Watson (the strand with 5' end at the left telomere) or 'C' for Crick (the complement strand, 5' end is at the right telomere).\n",
    "\n",
    "You can read about the yeast gene naming system here - http://seq.yeastgenome.org/help/community/nomenclature-conventions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Input data are in individual tab-delimited files, one for each experiment\n",
    "# Here I load each one into its own Pandas dataframe and create a list of frames\n",
    "#\n",
    "\n",
    "frames = []\n",
    "\n",
    "for file in os.listdir(\"Data\"):\n",
    "    if file.endswith(\".gbgout\"):\n",
    "        filepath = os.path.join(\"Data/\", file)\n",
    "        fs = file.split('_')\n",
    "        name = \"_\".join(fs[0:2])\n",
    "        frames.append(pd.read_csv(filepath, sep=\"\\t\", header = None, names=['Gene',name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# the list frames is a list of dataframes \n",
    "# this is what they look like\n",
    "#\n",
    "\n",
    "frames[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Combines all of the individual frames into one dataframe, combining on the \"Gene\" column\n",
    "# Column names are the data file\n",
    "#\n",
    "\n",
    "df = reduce(lambda  left,right: pd.merge(left,right,on=['Gene'], how='outer'), frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Sort columns by name for convenience\n",
    "#\n",
    "\n",
    "df = df.reindex_axis(sorted(df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Use only genes starting with \"Y\" which are protein-coding genes\n",
    "# You can come back and revisit this choice later if you want\n",
    "#\n",
    "\n",
    "df = df.loc[df['Gene'].str.startswith('Y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Index dataframe on 'Gene'\n",
    "#\n",
    "\n",
    "df = df.set_index('Gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save so we don't have to do all that again next time\n",
    "\n",
    "df.to_csv(\"Barton_combined_Ygenes.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's look at some data\n",
    "\n",
    "df.plot.scatter(x='WT_rep02',y='Snf2_rep02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# most of the points are packed in a small range with only a few large values\n",
    "# most common way to get around this is a log plot\n",
    "\n",
    "\n",
    "df.plot.scatter(x='WT_rep02',y='Snf2_rep02',logx = True, logy= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# well that didn't help - now there are values that are too small\n",
    "# let's set lower and upper bounds for the plot\n",
    "\n",
    "lower = 10\n",
    "upper = max(df['WT_rep02'].max(),df['Snf2_rep02'].max())\n",
    "\n",
    "\n",
    "df.plot.scatter(x='WT_rep02',y='Snf2_rep02',logx = True, logy= True, xlim=(lower,upper), ylim=(lower,upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# do a few other things to make this pretty\n",
    "# make points smaller with s=1\n",
    "# set the figure size to be square\n",
    "#\n",
    "\n",
    "df.plot.scatter(x='WT_rep02',y='Snf2_rep02', s=1,logx = True, logy= True, xlim=(lower,upper), ylim=(lower,upper), figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# we'd love to do this for all pairs of columns\n",
    "# let's start with a few\n",
    "#\n",
    "\n",
    "plot_columns = ['WT_rep01','WT_rep02','WT_rep03','Snf2_rep01','Snf2_rep02','Snf2_rep03']\n",
    "sm = scatter_matrix(df[plot_columns],s=1,figsize=(10,10),diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quickly gets impossible to look at. So let's try something different. Instead of trying to look at every cell scatterplot, let's summarize each scatterplot with a number, say the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper discusses problems with individual samples. One way to screen for this in a sample that's so large is to look within the two sets for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all columns\n",
    "\n",
    "colnames = df.columns.get_values()\n",
    "\n",
    "# create an empty matrix to store the correlations in\n",
    "\n",
    "corrdata = np.zeros( (len(colnames),len(colnames)))\n",
    "\n",
    "# loop through the columnames\n",
    "\n",
    "for i1,c1 in enumerate(colnames):\n",
    "    for i2,c2 in enumerate(colnames):\n",
    "        corrdata[i1][i2] = pearsonr(df[c1],df[c2])[0]\n",
    "        \n",
    "im = plt.imshow(corrdata)\n",
    "cb = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colormaps\n",
    "\n",
    "This images are made by mapping a 2D array of values into colors by dividing values between the min and the max of array into bins and assigning each a color using a python colormap. You might not be a huge fan of this particular colormap. Well fear not! Python gives you lots of options. You can see them here https://matplotlib.org/tutorials/colors/colormaps.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"Last plot made with cmap\", im.cmap.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's try again with magma\n",
    "\n",
    "im = plt.imshow(corrdata,cmap='magma')\n",
    "cb = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see from plot about that there are several problematic samples that have correlations that are outliars. How should we filter them? Simplest way would be to pick an average correlation to other samples as a cutoff. What should we choose? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Make a histogram of average correlation values\n",
    "#\n",
    "\n",
    "corrmeans = []\n",
    "for i1,c1 in enumerate(corrdata):\n",
    "    corrmeans.append(np.mean(c1))\n",
    "\n",
    "hist = plt.hist(corrmeans, bins=np.arange(0.5,1.0,.025))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most are above .95 so let's make that our cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames_filt = []\n",
    "for c1 in colnames:\n",
    "    d = []\n",
    "    for c2 in colnames:\n",
    "        d.append(pearsonr(df[c1],df[c2])[0])\n",
    "    d = np.array(d)\n",
    "    if np.mean(d) < 0.95:\n",
    "        print (\"Removing \",c1,np.mean(d))\n",
    "    else:\n",
    "        colnames_filt.append(c1)\n",
    "        \n",
    "colnames = colnames_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now replot \n",
    "\n",
    "corrdata = np.zeros( (len(colnames),len(colnames)))\n",
    "\n",
    "for i1,c1 in enumerate(colnames):\n",
    "    d = []\n",
    "    for i2,c2 in enumerate(colnames):\n",
    "        corrdata[i1][i2] = pearsonr(df[c1],df[c2])[0]\n",
    "        \n",
    "plt.imshow(corrdata,cmap='magma')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still some heterogeneity but looks a lot better - no egregious outliars - so we'll use this set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to think about: was this an ok thing to do?\n",
    "\n",
    "When is/isn't it ok to remove data that looks wonky, and how should you do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: \n",
    "\n",
    "Let's imagine we did an experiment with no replicates - one sample per consdition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's pick a pair of WT and snf2 experiments and see how they compare\n",
    "\n",
    "c1 = 'Snf2_rep01'\n",
    "c2 = 'WT_rep01'\n",
    "\n",
    "x = df[c1]\n",
    "y = df[c2]\n",
    "\n",
    "maxval = max(np.max(x),np.max(y))\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposx='clip')\n",
    "ax.set_xlim(1,maxval)\n",
    "ax.set_ylim(1,maxval)\n",
    "\n",
    "ax.scatter(x, y, s = 1, c='b', edgecolor = 'none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can already see a problem which is doesn't look like data fall along line x = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's pick a pair of WT and snf2 experiments and see how they compare\n",
    "\n",
    "# how well do these fit?\n",
    "\n",
    "c1 = 'Snf2_rep01'\n",
    "c2 = 'WT_rep01'\n",
    "\n",
    "# select data, remove really low values\n",
    "\n",
    "x = df[c1]\n",
    "y = df[c2]\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(1,maxval)\n",
    "ax.set_ylim(1,maxval)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposx='clip')\n",
    "ax.scatter(x, y, s = 1, c = 'black', edgecolor = 'none')\n",
    "ax.plot(x,x,'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!! Data should fall along line. We will return to this issue in a little bit but for now let's try another pair of samples.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's pick a pair of WT and snf2 experiments and see how they compare\n",
    "\n",
    "# how well do these fit?\n",
    "\n",
    "c1 = 'Snf2_rep02'\n",
    "c2 = 'WT_rep02'\n",
    "\n",
    "# select data, remove really low values\n",
    "\n",
    "x = df[c1]\n",
    "y = df[c2]\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(1,maxval)\n",
    "ax.set_ylim(1,maxval)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposx='clip')\n",
    "ax.scatter(x, y, s = 1, c = 'black', edgecolor = 'none')\n",
    "ax.plot(x,x,'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect, but a lot better. So now, how do we identify outliers? Many people start by saying genes up or down 2x. So let's look at those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pair to compare\n",
    "\n",
    "c1 = 'Snf2_rep02'\n",
    "c2 = 'WT_rep02'\n",
    "\n",
    "# select data, remove really low values\n",
    "\n",
    "x = df[c1][(df[c1] > 1) & (df[c2] > 1)] # throw out really small values\n",
    "y = df[c2][(df[c1] > 1) & (df[c2] > 1)]\n",
    "\n",
    "# set color and size of points based on X/Y ratio\n",
    "\n",
    "c = []\n",
    "s = []\n",
    "\n",
    "for i,vx in enumerate(x):    \n",
    "    if x[i]/y[i] > 2.0:\n",
    "        c.append('g')\n",
    "        s.append(3)\n",
    "    elif x[i]/y[i] < .5:\n",
    "        c.append('b')\n",
    "        s.append(3)\n",
    "    else:\n",
    "        c.append('k')\n",
    "        s.append(1)\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(1,maxval)\n",
    "ax.set_ylim(1,maxval)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposx='clip')\n",
    "ax.scatter(x, y, s = s, c = c, edgecolor = 'none')\n",
    "ax.plot(x,x,'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a lot of points! Should we believe them? Fortunately we can sanity check this because we actually have a lot more data. Let's start by comparing the Snf2/WT ratio in this pair of samples to a different pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wt1 = 'WT_rep02'\n",
    "wt2 = 'WT_rep03'\n",
    "mut1 = 'Snf2_rep02'\n",
    "mut2 = 'Snf2_rep03'\n",
    "\n",
    "cols = [wt1,wt2,mut1,mut2]\n",
    "\n",
    "# create a temporary data frame where any row with values < 1 are removed\n",
    "\n",
    "tdf = df[cols][df > 1].dropna()\n",
    "\n",
    "x = np.log2(tdf[wt1]/tdf[mut1])\n",
    "y = np.log2(tdf[wt2]/tdf[mut2])\n",
    "\n",
    "c = []\n",
    "s = []\n",
    "\n",
    "for i,vx in enumerate(x):    \n",
    "    if x[i] > 1.0: \n",
    "        if y[i] > 1.0:\n",
    "            c.append('g')\n",
    "            s.append(8)\n",
    "        else:\n",
    "            c.append('r')\n",
    "            s.append(8)\n",
    "    elif x[i] < -1.0:\n",
    "        if y[i] < -1.0:\n",
    "            c.append('g')\n",
    "            s.append(8)\n",
    "        else:\n",
    "            c.append('r')\n",
    "            s.append(8)\n",
    "    else:\n",
    "        c.append('k')\n",
    "        s.append(1)\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(-3,3)\n",
    "ax.set_ylim(-3,3)\n",
    "ax.scatter(x, y, s = s, c = c, edgecolor = 'none')\n",
    "#ax.plot(x,x,'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we need more than just one or two samples to accurately identify reproducible differences between samples. But how many do we need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now create lists for WT and Snf2 so we can start comparing them\n",
    "\n",
    "colnames_snf2 = []\n",
    "colnames_WT = []\n",
    "\n",
    "for c in colnames:\n",
    "    if c.startswith(\"Snf2\"):\n",
    "        colnames_snf2.append(c)\n",
    "    elif c.startswith(\"WT\"):\n",
    "        colnames_WT.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new columns that are averages\n",
    "\n",
    "df['Snf2_ave'] = df[colnames_snf2].mean(axis=1)\n",
    "df['WT_ave'] = df[colnames_WT].mean(axis=1)\n",
    "df['ave'] = df[colnames_snf2 + colnames_WT].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pair to compare\n",
    "\n",
    "c1 = 'WT_ave' \n",
    "c2 = 'Snf2_ave'\n",
    "\n",
    "# select data, remove really low values\n",
    "\n",
    "x = df[c1][(df[c1] > 1) & (df[c2] > 1)] # throw out really small values\n",
    "y = df[c2][(df[c1] > 1) & (df[c2] > 1)]\n",
    "\n",
    "# set color and size of points based on X/Y ratio\n",
    "\n",
    "c = []\n",
    "s = []\n",
    "\n",
    "for i,vx in enumerate(x):    \n",
    "    if x[i]/y[i] > 2.0:\n",
    "        c.append('g')\n",
    "        s.append(3)\n",
    "    elif x[i]/y[i] < .5:\n",
    "        c.append('b')\n",
    "        s.append(3)\n",
    "    else:\n",
    "        c.append('k')\n",
    "        s.append(1)\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(1,maxval)\n",
    "ax.set_ylim(1,maxval)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposx='clip')\n",
    "ax.set_xlabel(c1)\n",
    "ax.set_ylabel(c2)\n",
    "ax.scatter(x, y, s = s, c = c, edgecolor = 'none')\n",
    "ax.plot(x,x,'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at individual genes\n",
    "\n",
    "Now we are going to start looking at individual genes. The first thing we're doing to do is sort based on the magnitude of the ratio between the WT and Snf2 averages and then plot the individual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sort based ratio of snf2 ave vs wt ave\n",
    "\n",
    "aved = {}\n",
    "\n",
    "cols = ['WT_ave','Snf2_ave']\n",
    "tdf = df[cols][df > 10].dropna()\n",
    "\n",
    "for index, row in tdf.iterrows():\n",
    "    snf2 = row['Snf2_ave']\n",
    "    wt = row['WT_ave']\n",
    "    aved[index] = abs(np.log2(snf2/wt))\n",
    "    \n",
    "aved = {k:v for (k,v) in aved.items() if v > 1.0}\n",
    "\n",
    "aveds = sorted(aved.keys(),key = lambda x: aved[x], reverse=True)\n",
    "\n",
    "snf2_ind = []\n",
    "snf2 = []\n",
    "wt_ind = [] \n",
    "wt = []\n",
    "\n",
    "for i,t in enumerate(aveds[0:100]):\n",
    "    for c in colnames_snf2:\n",
    "        snf2_ind.append(i+1)\n",
    "        snf2.append(df.at[t,c])\n",
    "    for c in colnames_WT:\n",
    "        wt_ind.append(i+1)\n",
    "        wt.append(df.at[t,c])\n",
    "        \n",
    "fig = plt.figure(figsize = (10,.1*max(wt_ind)))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(1,max(wt + snf2))\n",
    "ax.set_ylim(max(wt_ind),0)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.scatter(wt,wt_ind,s=12,alpha=.25,c='r',edgecolor='none')\n",
    "ax.scatter(snf2,snf2_ind,s=12,alpha=.25,c='b',edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maybe median is a better value\n",
    "\n",
    "df['Snf2_med'] = df[colnames_snf2].median(axis=1)\n",
    "df['WT_med'] = df[colnames_WT].median(axis=1)\n",
    "df['med'] = df[colnames_snf2 + colnames_WT].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sort based ratio of snf2 ave vs wt ave\n",
    "\n",
    "aved = {}\n",
    "\n",
    "cols = ['WT_med','Snf2_med']\n",
    "tdf = df[cols][df > 10].dropna()\n",
    "\n",
    "for index, row in tdf.iterrows():\n",
    "    snf2 = row['Snf2_med']\n",
    "    wt = row['WT_med']\n",
    "    aved[index] = abs(np.log2(snf2/wt))\n",
    "    \n",
    "aved = {k:v for (k,v) in aved.items() if v > 1.0}\n",
    "\n",
    "aveds = sorted(aved.keys(),key = lambda x: aved[x], reverse=True)\n",
    "\n",
    "snf2_ind = []\n",
    "snf2 = []\n",
    "wt_ind = [] \n",
    "wt = []\n",
    "\n",
    "for i,t in enumerate(aveds[0:100]):\n",
    "    for c in colnames_snf2:\n",
    "        snf2_ind.append(i+1)\n",
    "        snf2.append(df.at[t,c])\n",
    "    for c in colnames_WT:\n",
    "        wt_ind.append(i+1)\n",
    "        wt.append(df.at[t,c])\n",
    "        \n",
    "fig = plt.figure(figsize = (10,.1*max(wt_ind)))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(1,max(wt + snf2))\n",
    "ax.set_ylim(max(wt_ind),0)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.scatter(wt,wt_ind,s=12,alpha=.25,c='r',edgecolor='none')\n",
    "ax.scatter(snf2,snf2_ind,s=12,alpha=.25,c='b',edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lets look at individual genes a bit closer\n",
    "\n",
    "gene = aveds[0]\n",
    "\n",
    "snf2 = []\n",
    "wt = []\n",
    "\n",
    "\n",
    "for c in colnames_snf2:\n",
    "    snf2.append(df.at[gene,c])\n",
    "for c in colnames_WT:\n",
    "    wt.append(df.at[gene,c])\n",
    "        \n",
    "h = plt.hist(wt, color = 'blue',label='WT')\n",
    "h = plt.hist(snf2, color = 'red',label='SNF2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (aveds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log transform values\n",
    "\n",
    "gene = aveds[0]\n",
    "\n",
    "snf2 = []\n",
    "wt = []\n",
    "\n",
    "\n",
    "for c in colnames_snf2:\n",
    "    snf2.append(np.log10(df.at[gene,c]))\n",
    "for c in colnames_WT:\n",
    "    wt.append(np.log10(df.at[gene,c]))\n",
    "        \n",
    "h = plt.hist(wt,color = 'blue',label='WT')\n",
    "h = plt.hist(snf2,color = 'red',label='SNF2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# log transform values\n",
    "\n",
    "gene = aveds[0]\n",
    "\n",
    "snf2 = []\n",
    "wt = []\n",
    "\n",
    "\n",
    "for c in colnames_snf2:\n",
    "    snf2.append(np.log2(df.at[gene,c]/df.at[gene,'Snf2_ave']))\n",
    "for c in colnames_WT:\n",
    "    wt.append(np.log2(df.at[gene,c]/df.at[gene,'WT_ave']))\n",
    "        \n",
    "h = plt.hist(wt, bins=np.arange(-3.00,3.00,0.5), color = 'blue',label='WT',alpha=0.25)\n",
    "h = plt.hist(snf2,bins=np.arange(-3.00,3.00,0.5), color = 'red',label='SNF2',alpha=0.25)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do the data fit a normal distribution and do we have enough data to do a fit\n",
    "\n",
    "gene = aveds[0]\n",
    "\n",
    "snf2 = []\n",
    "wt = []\n",
    "\n",
    "for c in colnames_snf2:\n",
    "    snf2.append(df.at[gene,c])\n",
    "for c in colnames_WT:\n",
    "    wt.append(df.at[gene,c])\n",
    "\n",
    "# Fit a normal distribution to the data:\n",
    "wt_mu, wt_std = norm.fit(wt)\n",
    "snf2_mu, snf2_std = norm.fit(snf2)\n",
    "\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "plt.hist(wt, bins=15, normed=True, alpha=0.6, color='blue')\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, wt_mu, wt_std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit results: mu = %.2f,  std = %.2f\" % (wt_mu, wt_std)\n",
    "plt.title(title)\n",
    "\n",
    "ax = plt.subplot(2, 1, 2)\n",
    "plt.hist(snf2, bins=15, normed=True, alpha=0.6, color='blue')\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, snf2_mu, snf2_std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit results: mu = %.2f,  std = %.2f\" % (snf2_mu, snf2_std)\n",
    "plt.title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do the data fit a normal distribution and do we have enough data to do a fit\n",
    "\n",
    "gene = aveds[0]\n",
    "\n",
    "snf2 = []\n",
    "wt = []\n",
    "\n",
    "for c in colnames_snf2:\n",
    "    snf2.append(df.at[gene,c])\n",
    "for c in colnames_WT:\n",
    "    wt.append(df.at[gene,c])\n",
    "\n",
    "# Fit a normal distribution to the data:\n",
    "wt_std, loc, wt_mean = mu, loc, mean = lognorm.fit(wt, floc=0)\n",
    "snf2_std, loc, snf2_mean = lognorm.fit(snf2, floc=0)\n",
    "\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "plt.hist(wt, bins=15, normed=True, alpha=0.6, color='blue')\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = lognorm.pdf(x, wt_mu, wt_std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit results: mu = %.2f,  std = %.2f\" % (wt_mu, wt_std)\n",
    "plt.title(title)\n",
    "\n",
    "ax = plt.subplot(2, 1, 2)\n",
    "plt.hist(snf2, bins=15, normed=True, alpha=0.6, color='blue')\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = lognorm.pdf(x, snf2_mu, snf2_std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit results: mu = %.2f,  std = %.2f\" % (snf2_mu, snf2_std)\n",
    "plt.title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to do some statistics\n",
    "\n",
    "Probably better to treat this as a non-parametric test. The test most commonly used to ask if two distributions are different is the Kolmogorov-Smirnov test. https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do the data fit a normal distribution and do we have enough data to do a fit\n",
    "\n",
    "gene = aveds[0]\n",
    "\n",
    "snf2 = []\n",
    "wt = []\n",
    "\n",
    "for c in colnames_snf2:\n",
    "    snf2.append(df.at[gene,c])\n",
    "for c in colnames_WT:\n",
    "    wt.append(df.at[gene,c])\n",
    "    \n",
    "print(ks_2samp(wt,snf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do the data fit a normal distribution and do we have enough data to do a fit\n",
    "\n",
    "gene = aveds[0]\n",
    "\n",
    "snf2 = []\n",
    "wt = []\n",
    "\n",
    "for c in colnames_snf2:\n",
    "    snf2.append(df.at[gene,c])\n",
    "for c in colnames_WT:\n",
    "    wt.append(df.at[gene,c])\n",
    "    \n",
    "print(ks_2samp(wt,snf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ksv = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    snf2 = row[colnames_snf2]\n",
    "    wt = row[colnames_WT]\n",
    "    ksv[index] = -np.log10(ks_2samp(wt,snf2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ksv = {k:v for (k,v) in ksv.items() if v > 10.0}\n",
    "\n",
    "ksvs = sorted(ksv.keys(),key = lambda x: ksv[x], reverse=True)\n",
    "\n",
    "snf2_ind = []\n",
    "snf2 = []\n",
    "wt_ind = [] \n",
    "wt = []\n",
    "\n",
    "for i,t in enumerate(ksvs[0:100]):\n",
    "    for c in colnames_snf2:\n",
    "        snf2_ind.append(i+1)\n",
    "        snf2.append(df.at[t,c])\n",
    "    for c in colnames_WT:\n",
    "        wt_ind.append(i+1)\n",
    "        wt.append(df.at[t,c])\n",
    "        \n",
    "fig = plt.figure(figsize = (10,.1*max(wt_ind)))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlim(1,max(wt + snf2))\n",
    "ax.set_ylim(max(wt_ind),0)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.scatter(wt,wt_ind,s=12,alpha=.25,c='r',edgecolor='none')\n",
    "ax.scatter(snf2,snf2_ind,s=12,alpha=.25,c='b',edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replicates = 100000\n",
    "m1 = 1000\n",
    "m2 = 500\n",
    "v = .29\n",
    "\n",
    "wt = np.random.lognormal(np.log(m1),v,replicates)\n",
    "mut = np.random.lognormal(np.log(m2),v,replicates)\n",
    "\n",
    "ks_2samp(wt,mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = plt.hist(np.log(wt),bins=50,alpha=0.5,normed=True)\n",
    "x = plt.hist(np.log(mut),bins=50,alpha=0.5,normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# lets look at the effect of changing the number of experiments we did\n",
    "#\n",
    "\n",
    "pvals = {}\n",
    "\n",
    "trials = 100\n",
    "\n",
    "sample_sizes = [5,10,15,20,25,30,35,40,45,50]\n",
    "sample_sizes = [2,3,4,5,6,7,8,9,10,15,20]\n",
    "for n in sample_sizes:\n",
    "    pvals[n] = []\n",
    "    for t in range(0,trials):\n",
    "        wtr = np.random.choice(wt,n)\n",
    "        mutr = np.random.choice(mut,n)\n",
    "        pvals[n].append(-np.log10(ks_2samp(wtr,mutr)[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "\n",
    "axes.violinplot(dataset = [pvals[v] for v in sample_sizes])\n",
    "axes.set_title('')\n",
    "axes.yaxis.grid(False)\n",
    "axes.set_xlabel('Sample Size')\n",
    "axes.set_ylabel('KS p-values')\n",
    "a = plt.xticks(range(1,len(sample_sizes)+1),sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
